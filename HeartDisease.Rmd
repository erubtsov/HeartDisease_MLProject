---
output:
  pdf_document: default
  html_document: default
---

```{r}

library(dplyr)
library(readr)
library(pROC)
library(tidymodels)
library(workflows)
library(caret)
library(glmnet)

```

```{r}

# Set the file path to your "heart.csv" file
file_path <- "/data/accounts/fa23/ericrubtsov/DSCI445/DSCI 445 Heart Disease Project/heart.csv"

# Read the CSV file into a data frame
heart_data <- read_csv(file_path)

# Display the first few rows of the data for inspection
print(heart_data)

# Subset the dataset to include only numerical columns
numerical_data <- heart_data[sapply(heart_data, is.numeric)]

# Apply the summary function to generate summary statistics
summary_stats <- summary(numerical_data)

# Print the well-formatted summary statistics
print(summary_stats)
```


```{r}
na_values <- any(is.na(heart_data))
# Display the result
if (na_values) {
  cat("There are NA values in the dataset.\n")
  # Display the count of NA values for each column
  col_na_count <- colSums(is.na(heart_data))
  print("Col NA: ", col_na_count)
} else {
  cat("There are no NA values in the dataset.\n")
}
```

```{r}

# Function to identify outliers using IQR for a given column
identify_outliers <- function(column) {
  if (is.numeric(column)) {
    q1 <- quantile(column, 0.25)
    q3 <- quantile(column, 0.75)
    iqr <- q3 - q1
    lower_bound <- q1 - 1.5 * iqr
    upper_bound <- q3 + 1.5 * iqr
    outliers <- column < lower_bound | column > upper_bound
    return(outliers)
  } else {
    # If the column is not numeric, return a logical vector of the same length
    return(rep(FALSE, length(column)))
  }
}

# Apply the function to each numerical column in the dataset
numerical_columns <- sapply(heart_data, is.numeric)

# Initialize an empty data frame to store outlier information
outliers_df <- data.frame(variable = character(0), value = logical(0))

# Initialize a list to store histogram objects
histograms <- list()

# Loop through each numerical column
for (col in names(heart_data[, numerical_columns])) {
  outliers <- identify_outliers(heart_data[, col])
  
  # Check if there are outliers before attempting to append to the data frame
  if (any(outliers)) {
    outliers_df <- rbind(outliers_df, data.frame(variable = rep(col, sum(outliers)), value = outliers))
  }

  # Create histogram for the column
  hist_obj <- ggplot(heart_data, aes(x = get(col))) +
    geom_histogram(fill = "skyblue", color = "black", bins = 20) +
    labs(title = paste("Histogram for", col), x = col, y = "Frequency") +
    theme_minimal()
  
  # Append the histogram object to the list
  histograms[[col]] <- hist_obj
}

# Display the data frame with outliers
print(outliers_df)

# Display the histograms
for (col in names(histograms)) {
  print(histograms[[col]])
}

#The target histogram takes values 0 and 1, indicating the presence of heart disease or not
```

```{r}
# Filter rows with chol > 500
rows_chol_gt_500 <- heart_data[heart_data$chol > 500, ]

# Display the rows
print(rows_chol_gt_500)


# Specify the columns based on which you want to identify duplicates
columns_to_check <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", "oldpeak", "slope", "ca", "thal", "target")

# Remove duplicates based on the specified columns
heart_data_clean <- distinct(heart_data, !!!syms(columns_to_check))

# View the updated dataframe
print(heart_data_clean)
```

```{r}
# Initialize a list to store histogram objects
histograms <- list()

# Loop through each numerical column
for (col in names(heart_data_clean[, numerical_columns])) {

  # Create histogram for the column
  hist_obj <- ggplot(heart_data, aes(x = get(col))) +
    geom_histogram(fill = "skyblue", color = "black", bins = 20) +
    labs(title = paste("Histogram for", col), x = col, y = "Frequency") +
    theme_minimal()
  
  # Append the histogram object to the list
  histograms[[col]] <- hist_obj
}

# Display the data frame with outliers
print(outliers_df)

# Display the histograms
for (col in names(histograms)) {
  print(histograms[[col]])
  
#Dropping the duplicate values reduces the dataset to 302 rows. The distributions among the columns stay the same, so removing duplicates did not adversely affect the information given by the original data set
}
```

```{r}


# Read the CSV file into a data frame
heart_data <- read_csv(file_path)

# Display the structure and summary of the dataset
str(heart_data)
summary(heart_data_clean)

# Identify categorical and continuous variables
categorical_vars <- c("sex", "cp", "fbs", "restecg", "exang", "slope", "ca", "thal", "target")
continuous_vars <- setdiff(names(heart_data_clean), categorical_vars)

# Visualize the distribution of continuous variables (correlation matrix)
correlation_matrix <- cor(heart_data[, continuous_vars])
ggplot(data = as.data.frame(as.table(correlation_matrix)), aes(Var1, Var2, fill = Freq)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0, limit = c(-1, 1), space = "Lab",
                       name = "Correlation") +
  theme_minimal() +
  labs(title = "Correlation Matrix for Continuous Variables")

library(patchwork)
# Function to create association plot for a categorical variable without individual titles
create_association_plot <- function(var) {
  ggplot(heart_data, aes(x = as.factor(.data[[var]]), fill = as.factor(target))) +
    geom_bar(position = "fill") +
    labs(x = var, y = "Proportion") +
    scale_fill_manual(values = c("0" = "blue", "1" = "red")) +
    theme(axis.title.x = element_text(size = 10),  # Adjust x-axis title size
          axis.text.x = element_text(size = 8, angle = 45, hjust = 1),  # Adjust x-axis text size and rotation
          plot.title = element_text(size = 12, hjust = 0.5, margin = margin(b = 10)))  # Adjust main title size and margin
}

# Create association plots without individual titles
association_plots <- lapply(categorical_vars, create_association_plot)

# Combine plots onto one page with adjusted margins and spacing
association_plots_combined <- wrap_plots(association_plots, ncol = 3, guides = 'collect') +
  plot_layout(widths = c(1, 1, 1), heights = c(1, 1, 1), guides = 'collect') +
  ggtitle("Associations between variables and target")  # Add main title

# Print the combined plot
print(association_plots_combined)

```

The correlation matrix provides insight on the variable trends with respect to each other. The plot shows that there are more notable negative correlations within the metrics. One such negative correlation would be 'Age' and 'Thalach'. This strong negative correlation indicates that as age increases, maximum heart rate tends to decrease, which makes sense. Other sensible ne

```{r}
# Scatter plot for Cholesterol Levels (chol) and Exercise-Induced Angina (exang)
scatter_chol_exang <- ggplot(heart_data, aes(x = chol, y = exang, color = as.factor(exang))) +
  geom_point() +
  labs(title = "Cholesterol Levels vs. Exercise-Induced Angina",
       x = "Cholesterol Levels",
       y = "Exercise-Induced Angina") +
  scale_color_manual(values = c("0" = "blue", "1" = "red")) +
  theme_minimal()

# Scatter plot for Resting Blood Pressure (trestbps) and Exercise-Induced Angina (exang)
scatter_trestbps_exang <- ggplot(heart_data, aes(x = trestbps, y = exang, color = as.factor(exang))) +
  geom_point() +
  labs(title = "Resting Blood Pressure vs. Exercise-Induced Angina",
       x = "Resting Blood Pressure",
       y = "Exercise-Induced Angina") +
  scale_color_manual(values = c("0" = "blue", "1" = "red")) +
  theme_minimal()

# Display the scatter plots side by side
library(gridExtra)
grid.arrange(scatter_chol_exang, scatter_trestbps_exang, ncol = 2)
```


The Chi-squared tests are run on each categorical variable to assess whether there is significant association between that variable and the target variable (heart disease or not)

```{r}
# Assuming `target` is the binary outcome variable of interest
categorical_vars <- c("sex", "cp", "fbs", "restecg", "exang", "slope", "ca", "thal")

# Run chi-squared tests for each categorical variable
chi_squared_results <- lapply(categorical_vars, function(var) {
  contingency_table <- table(heart_data_clean[[var]], heart_data_clean$target)
  chi_squared_test_result <- chisq.test(contingency_table)
  return(list(variable = var, chi_squared_test = chi_squared_test_result))
})

# Print results
for (result in chi_squared_results) {
  cat("Chi-squared test for", result$variable, ":\n")
  print(result$chi_squared_test)
  cat("\n")
}
```

```{r}

# Set a random seed for reproducibility
set.seed(445)

# Create an index for the train-test split
index <- createDataPartition(heart_data_clean$target, p = 0.8, list = FALSE)

summary(heart_data_clean)

# Split the data into training and testing sets
train_data <- heart_data_clean[index, ]
test_data <- heart_data_clean[-index, ]

# Display the dimensions of the training and testing sets
cat("\nTraining set dimensions:", dim(train_data), "\n")
cat("Testing set dimensions:", dim(test_data), "\n")

```

TODO  (Sarah?): Logit model assumptions. Understand if the data meets these assumptions.

It is important to discuss the assumptions of the underlying data when fitting a logistic regression model. The first assumption is the linearity of log-odds, which means that the relationship between the independent variables and the log-odds of the dependent variable is linear. Other model assumptions include the observations of the datset being independent of each other, independent variables are not highly correlated with each other, homoscedascity of residuals, no outliers or influential points, and a Binary outcome variable. 

We have established in our correlation matrix that there are negatively correlated


```{r}
# Fit logistic regression model
logistic_model <- glm(target ~ age + sex + cp + trestbps + chol + fbs + restecg +
                      thalach + exang + oldpeak + slope + ca + thal,
                      data = heart_data_clean, family = "binomial")

# Print summary of the model
summary(logistic_model)


# Predict on the test data
predicted_probs <- predict(logistic_model, newdata = test_data, type = "response")
 
```
Fitting a logistic regression model, the independent variables with a p-value < 0.05 can be interpreted as such:

The estimated coefficient for 'sex' is -1.751, indicating that being female is associated with a 1.751 decrease in the log odds of having heart disease compared to being male.

The estimated coefficient for chest pain (cp) indicates a 0.85 increase in log odds of having heart disease for every one unit increase in the categorical representation of chest pain.

The model indicates that a one unit increase in resting blood pressure (trestbps) is associated with a 0.018 decrease in the log odds of having heart disease.

The model also indicates that cholesterol is a significant predictor, with a decrease of 0.004489 in the log odds of having heart disease for every 1 unit increase in cholesterol. This does not seem reasnable, as a significant increase in cholesterol would surely increase the probability of heart disease. This demonstrates the importance of having a decent understanding of data one is working with, because this discovery indicates that the model assumptions for logistic regression must be reevaluated. The most likely assumption to be violated is the absence of multicollinearity, given the interconnecting nature of physical health and the corresponding features in the data frame.

Other significant predictors include resting electrocardiograph results (restecg), maximum heart rate achieved during exercise (thalach), exercise induced angia (exang), oldpeak, the slope of the peak exercises, number of major vessels colored by fluoroscopy (ca), and Thallium stress testing (thal), which is a type of nuclear imaging test used to evaluate blood flow to the heart.

The inferences made in this discussion were for example purposes, and can be applied similarly to the other significant predictors. The associated change in log odds and respective p-values for these predictors are referenced in the summary above.

The encoded categorical variables for chest pain and thal are ordinal, which means that their order in the encoding is ranked by increasing severity for predicting heart disease.

From the logistic regression model, it appears that certain significant predictors increasing by 1 are associated with a decrease in the log odds of having heart disease. More investigation can be done in these areas to understand the true relationships.

```{r}
true_labels <- test_data$target

predicted_probs <- predict(logistic_model, newdata = test_data, type = "response")

# Convert predicted probabilities to binary predictions (0 or 1)
predicted_labels <- ifelse(predicted_probs > 0.5, 1, 0)

# Confusion Matrix
conf_matrix <- table(True_Labels = true_labels, Predicted_Labels = predicted_labels)
print("Confusion Matrix:")
print(conf_matrix)

# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
print(paste("Accuracy:", round(accuracy, 4)))

# Specificity
specificity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])
print(paste("Specificity:", round(specificity, 4)))

# Sensitivity (True Positive Rate or Recall)
tp <- sum(predicted_labels == 1 & true_labels == 1)
fn <- sum(predicted_labels == 0 & true_labels == 1)
sensitivity <- tp / (tp + fn)

print(paste("Sensitivity:", round(sensitivity, 4)))

# Create ROC curve
roc_curve <- roc(true_labels, predicted_probs)

# Plot ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)

# Add AUC value to the plot
auc_value <- round(auc(roc_curve), 3)
text(0.7, 0.2, paste("AUC =", auc_value), col = "red", cex = 1.2)

# Calculate sensitivity and specificity for various thresholds
roc_points <- coords(roc_curve, "best", ret = c("threshold", "sens", "spec"))
print("Threshold, Sensitivity, Specificity:")
print(roc_points)

```
Accuracy = (TN + TP)/(TN + FN + TP + FP)
Sensitivity = TP/(TP + FN)
Specificity = TN/(TN + FP)

The specificity of 96.97% suggests that the model performed very well in correctly identifying instances without heart disease (class 0). This is important for ruling out individuals who do not have heart disease.

The sensitivity of 96.97% indicates that the model performed well in correctly identifying individuals with heart disease (class 1). This is crucial for detecting individuals who actually have heart disease.

The high specificity and sensitivity values are promising, suggesting that your model is effective in both ruling out healthy individuals and identifying those with heart disease. Overall,the logistic regression model is well performing.

Health data often exhibits multicollinearity, so applying ridge regression will retain the features while also shrinking them down to prevent over fitting. 

```{r}
set.seed(445) 
split_index <- createDataPartition(heart_data_clean$target, p = 0.8, list = FALSE)
train_data <- heart_data_clean[split_index, ]
test_data <- heart_data_clean[-split_index, ]

# Convert target variable to factor
train_data$target <- factor(train_data$target, levels = c(0, 1))
test_data$target <- factor(test_data$target, levels = c(0, 1))


# Ridge Regression Model
ridge_model <- train(
  target ~ ., 
  data = train_data,
  method = "glmnet",
  trControl = trainControl(method = "cv", number = 5),  # Cross-validation with 5 folds
  tuneGrid = expand.grid(alpha = 0, lambda = seq(0.1, 1, by = 0.1))  # Adjust lambda values
)

# Model Evaluation
predictions_logistic <- predict(logistic_model, newdata = test_data, type = "response")
predictions_ridge <- predict(ridge_model, newdata = test_data)

# Evaluate Ridge Regression Model
ridge_confusion <- confusionMatrix(predictions_ridge, test_data$target, positive = "1")
print("Ridge Regression Model:")
print(ridge_confusion)
```
Ridge regression was chosen as an approach for fitting a model for a few reasons. As mentioned earlier, multicollinearity in health data is ever-present and must be handled appropriately. Shrinking the coefficients of highly correlated variables makes the model more stable by preventing over fitting to the test data and reducing sensitivity to variation in the the data. This leads to improved generalization on unseen data. Finally, ridge regression can extend its regularization principles to logistic regression models, which is necessary for the binary target variable (heart disease or not).

In the context of heart disease classification, it is critical to minimize the number of false negatives. The consequences for false negatives would be much greater than false positives, so creating a model that airs on the side of caution for the patients would be the best model. For this reason, sensitivity is the most important metric. This model correctly captures 97% of positive instances which is quite good. 

Similar to Ridge regression, Lasso regression adds a regularization term (lambda) to the logistic regression cost function to penalize large coefficients. The key difference between the two is that Ridge regression uses Mean Squared Error as the basis for the its cost function and Lasso regression uses logistic loss as the basis of its cost function. Logistic loss is the negative log likelihood of the observed labels given the predicted probabilities. For Lasso regression, the regularization term drives the less important features to 0. With this, its main advantage is feature selection, along with the similar advantages of ridge regression.

Given the multicollinearity, It is important to consider that the Lasso method makes the less significant variable coefficients exactly 0, whereas the Ridge method just shrinks the coefficients. Less severe collinearity would favor the Lasso method because its penalty term that is based off of the absolute value of the coefficients will lead to a model with only the most relevant features. However, highly correlated variables may be favored by ridge regression since the penalty term is distributed between the less significant variables more evenly. Assessing model performance for both methods is good practice. Lasso regression is performed below:

```{r}

# Convert the target variable to a factor with consistent levels
heart_data_clean$target <- factor(heart_data_clean$target, levels = c(0, 1))

# Split the data into training and testing sets
set.seed(445)  # Set seed for reproducibility
sample_indices <- sample(seq_len(nrow(heart_data_clean)), size = 0.8 * nrow(heart_data_clean))
train_data <- heart_data_clean[sample_indices, ]
test_data <- heart_data_clean[-sample_indices, ]

# Fit the logistic regression model
logistic_model <- glm(target ~ age + sex + cp + trestbps + chol + fbs + 
                      restecg + thalach + exang + oldpeak + slope + ca + thal,
                      data = train_data, family = "binomial")


# Extract the predictor matrix and response vector
X_train <- model.matrix(target ~ ., data = train_data)[, -1]
y_train <- as.numeric(train_data$target) - 1  # Convert to 0 and 1

# Fit the Lasso model using cross-validation
lasso_model <- cv.glmnet(X_train, y_train, family = "binomial", alpha = 1)

# Make predictions on the test set
X_test <- model.matrix(target ~ ., data = test_data)[, -1]
predictions_lasso <- predict(lasso_model, s = "lambda.min", newx = X_test, type = "response")


# Evaluate the Lasso regression model
conf_matrix_lasso <- table(observed = test_data$target, predicted = ifelse(predictions_lasso > 0.5, 1, 0))


# Print evaluation metrics for Lasso regression
cat("\nLasso Regression Metrics:\n")
conf_matrix_lasso
accuracy_lasso <- sum(diag(conf_matrix_lasso)) / sum(conf_matrix_lasso)
sensitivity_lasso <- conf_matrix_lasso[2, 2] / sum(conf_matrix_lasso[2, ])
specificity_lasso <- conf_matrix_lasso[1, 1] / sum(conf_matrix_lasso[1, ])
cat("Accuracy:", accuracy_lasso, "\n")
cat("Sensitivity:", sensitivity_lasso, "\n")
cat("Specificity:", specificity_lasso, "\n")

lasso_model_cv <- cv.glmnet(X_train, y_train, family = "binomial", alpha = 1)

# Plot the cross-validated deviance
plot(lasso_model_cv)

# Identify the optimal lambda value
optimal_lambda <- lasso_model_cv$lambda.min
cat("Optimal Lambda:", optimal_lambda, "\n")

# Make predictions on the test set with the optimal lambda
predictions_lasso_cv <- predict(lasso_model_cv, s = optimal_lambda, newx = X_test, type = "response")

# Evaluate the Lasso regression model with cross-validation
conf_matrix_lasso_cv <- table(observed = test_data$target, predicted = ifelse(predictions_lasso_cv > 0.5, 1, 0))

# Print evaluation metrics for Lasso regression with cross-validation
cat("\nLasso Regression Metrics with Cross-Validation:\n")
conf_matrix_lasso_cv
accuracy_lasso_cv <- sum(diag(conf_matrix_lasso_cv)) / sum(conf_matrix_lasso_cv)
sensitivity_lasso_cv <- conf_matrix_lasso_cv[2, 2] / sum(conf_matrix_lasso_cv[2, ])
specificity_lasso_cv <- conf_matrix_lasso_cv[1, 1] / sum(conf_matrix_lasso_cv[1, ])
cat("Accuracy:", accuracy_lasso_cv, "\n")
cat("Sensitivity:", sensitivity_lasso_cv, "\n")
cat("Specificity:", specificity_lasso_cv, "\n")
```

```{r}

```
